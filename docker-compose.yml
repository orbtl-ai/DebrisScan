version: '3.2'

services:
  backend:
    container_name: debrisscan-backend
    image: redis:6.2.6-alpine
    ports:
      - "6379:6379"
    networks:
      - debrisscan-network
    command: redis-server

  client:
    build:
      context: .
      dockerfile: Docker/Local/Dockerfile.Client
    container_name: debrisscan-client
    links:
      - backend:backend
    ports:
      - "8080:8080"
      #- "7860:7860"
    networks:
      - debrisscan-network
    volumes:
      - type: bind
        source: ~/Documents/app_data
        target: /app_data
        read_only: false
      - type: bind
        source: ~/Documents/git/DebrisScan/app
        target: /app
        read_only: false
    env_file:
      - .env.dev
    command: gradio client/app.py  # enables "reload mode" as of Gradio 3.1
    #command: python /app/client/app.py
    depends_on:
      - backend

  geoprocessor:
    build:
      context: .
      dockerfile: Docker/Local/Dockerfile.Geoprocessor
    container_name: debrisscan-geoprocessor
    links:
      - backend:backend
      - tf-server:tf-server
    networks:
      - debrisscan-network
    volumes:
      - type: bind
        source: ~/Documents/app_data
        target: /app_data
        read_only: false
      - type: bind
        source: ~/Documents/git/DebrisScan/app
        target: /app
        read_only: false
    env_file:
      - .env.dev
    command: celery -A geoprocessor.tasks.celery_app worker --loglevel=info --concurrency=1 #--uid=nobody --gid=nogroup
    depends_on:
      - backend
      - client

  # NOTE: we're currently attaching a GPU in the override. Without this the below
  # worker is an unoptimized CPU worker.
  tf-server:
    build:
      context: .
      dockerfile: Docker/Local/Dockerfile.TFServing
    container_name: debrisscan-tf-server
    links:
      - backend:backend
    ports:
      - "8500:8500"
      - "8501:8501"
    networks:
      - debrisscan-network
    volumes:
      - type: bind
        source: ~/Documents/app_data
        target: /app_data
        read_only: false
    #environment:
    #  MODEL_NAME: efficientdet-d0
    #  OMP_NUM_THREADS: 4                          # replace by the number of cores
    #  TENSORFLOW_INTER_OP_PARALLELISM: 2
    #  TENSORFLOW_INTRA_OP_PARALLELISM: 4          # replace by the number of cores
    command:
      - --model_config_file=/app/tf_server/configs/models.config
      - --rest_api_timeout_in_ms=120000
    # - --batching_parameters_file=/app/core/batching.config
    # - --enable_batching
    # attach GPU support here
    #deploy:
    #  resources:
    #    reservations
    #      devices:
    #        - driver: nvidia
    #          count: 1
    #          capabilities: [gpu]

  flower:
    image: mher/flower:0.9.7
    container_name: debrisscan-flower
    #command: ["flower", "--broker=${CELERY_BROKER_URL}", "--port=5555", "--inspect_timeout=10000"] # the "Inspect method... failed" is still occuring. Waiting for worker? Feed it the app directly?
    links:
      - backend:backend
    networks:
      - debrisscan-network
    ports:
      - "5555:5555"
    env_file:
      - .env.dev
    depends_on:
      - backend

networks:
  debrisscan-network:
    driver: bridge